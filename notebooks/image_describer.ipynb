{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '../image_data/outfit.JPG'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the BLIP model from Hugging Face to generate a detailed description for the image:\n",
    "\n",
    "### Extract information from the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shahab/.pyenv/versions/3.10.6/envs/review_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processor and model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "def generate_detailed_description(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Prepare the image\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate a caption\n",
    "    out = model.generate(**inputs)\n",
    "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    # Generate a detailed description using the caption as context\n",
    "    prompt = f\"Describe the image in detail for a blind person can sense it: {caption}\"\n",
    "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\")\n",
    "    out = model.generate(**inputs, max_new_tokens=200)  # Set max_new_tokens to handle longer output\n",
    "    detailed_description = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    return detailed_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shahab/.pyenv/versions/3.10.6/envs/review_env/lib/python3.10/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Description: describe the image in detail for a blind person can sense it : a man wearing a black leather jacket, white sneakers and a scarf scarf and\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "description = generate_detailed_description(image_path)\n",
    "print(\"Generated Description:\", description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Generate Detailed Description Using GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the API key from the environment variable\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Set the API key for the OpenAI client\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_caption(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    # Prepare the image\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate a caption\n",
    "    out = model.generate(**inputs)\n",
    "    caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "def generate_detailed_description(caption):\n",
    "    prompt = f\"Provide a detailed description of the following image: {caption}\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",  # or \"gpt-4\"\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert at describing images in detail.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    detailed_description = response['choices'][0]['message']['content'].strip()\n",
    "    return detailed_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Description: The image features a man standing in a stylish outfit. He is wearing a sleek black leather jacket that reaches his waist, exuding a sense of sophistication and edginess. The jacket appears to be well-fitted with distinct stitching details that add a touch of character.\n",
      "\n",
      "His feet are adorned with crisp white sneakers, contrasting nicely against the dark jacket. The sneakers appear clean and modern, with a simple and versatile design that complements his overall look.\n",
      "\n",
      "Around his neck, the man is sporting a scarf, adding an element of warmth and style to his ensemble. The scarf is wrapped around his neck neatly, with its fabric draping elegantly against his jacket. The color and texture of the scarf are not clear from the description, but one can imagine it adding a pop of color or pattern to his outfit.\n",
      "\n",
      "Overall, the man’s outfit exudes a sense of contemporary fashion with a mix of casual and trendy elements. His choice of clothing reflects a modern and confident style, suitable for various occasions and environments.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "caption = generate_caption(image_path)  # Ensure this function is defined in your script\n",
    "description = generate_detailed_description(caption)\n",
    "print(\"Generated Description:\", description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gtts in /home/shahab/.pyenv/versions/3.10.6/envs/review_env/lib/python3.10/site-packages (2.5.1)\n",
      "Collecting playsound\n",
      "  Using cached playsound-1.3.0.tar.gz (7.7 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[23 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/shahab/.pyenv/versions/3.10.6/envs/review_env/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 353, in <module>\n",
      "  \u001b[31m   \u001b[0m     main()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/shahab/.pyenv/versions/3.10.6/envs/review_env/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 335, in main\n",
      "  \u001b[31m   \u001b[0m     json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "  \u001b[31m   \u001b[0m   File \"/home/shahab/.pyenv/versions/3.10.6/envs/review_env/lib/python3.10/site-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return hook(config_settings)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-e3xrtf90/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 327, in get_requires_for_build_wheel\n",
      "  \u001b[31m   \u001b[0m     return self._get_build_requires(config_settings, requirements=[])\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-e3xrtf90/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 297, in _get_build_requires\n",
      "  \u001b[31m   \u001b[0m     self.run_setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-e3xrtf90/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 497, in run_setup\n",
      "  \u001b[31m   \u001b[0m     super().run_setup(setup_script=setup_script)\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-build-env-e3xrtf90/overlay/lib/python3.10/site-packages/setuptools/build_meta.py\", line 313, in run_setup\n",
      "  \u001b[31m   \u001b[0m     exec(code, locals())\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 6, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/home/shahab/.pyenv/versions/3.10.6/lib/python3.10/inspect.py\", line 1147, in getsource\n",
      "  \u001b[31m   \u001b[0m     lines, lnum = getsourcelines(object)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/shahab/.pyenv/versions/3.10.6/lib/python3.10/inspect.py\", line 1129, in getsourcelines\n",
      "  \u001b[31m   \u001b[0m     lines, lnum = findsource(object)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/shahab/.pyenv/versions/3.10.6/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "  \u001b[31m   \u001b[0m     raise OSError('could not get source code')\n",
      "  \u001b[31m   \u001b[0m OSError: could not get source code\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "#!pip install gtts pygame\n",
    "!pip install gtts playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.10.6)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'playsound'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgtts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gTTS\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygame\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplaysound\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m playsound\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'playsound'"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "import pygame\n",
    "#from playsound import playsound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from openai import OpenAI\n",
    "def text_to_speech(description):\n",
    "    client = OpenAI()\n",
    "    response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"alloy\",\n",
    "        input=description,\n",
    "    )\n",
    "\n",
    "    audio = response.stream_to_file(\"output.mp3\")\n",
    "    return audio'''\n",
    "\n",
    "def text_to_speech(description):\n",
    "    tts = gTTS(description)\n",
    "    tts.save(\"../sounds/description.mp3\")\n",
    "\n",
    "    #pygame.mixer.init()\n",
    "    #pygame.mixer.music.load(\"description.mp3\")\n",
    "    #pygame.mixer.music.play()\n",
    "\n",
    "    #while pygame.mixer.music.get_busy():\n",
    "    #    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Description: The image features a man standing in a stylish outfit. He is wearing a sleek black leather jacket that reaches his waist, exuding a sense of sophistication and edginess. The jacket appears to be well-fitted with distinct stitching details that add a touch of character.\n",
      "\n",
      "His feet are adorned with crisp white sneakers, contrasting nicely against the dark jacket. The sneakers appear clean and modern, with a simple and versatile design that complements his overall look.\n",
      "\n",
      "Around his neck, the man is sporting a scarf, adding an element of warmth and style to his ensemble. The scarf is wrapped around his neck neatly, with its fabric draping elegantly against his jacket. The color and texture of the scarf are not clear from the description, but one can imagine it adding a pop of color or pattern to his outfit.\n",
      "\n",
      "Overall, the man’s outfit exudes a sense of contemporary fashion with a mix of casual and trendy elements. His choice of clothing reflects a modern and confident style, suitable for various occasions and environments.\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Description:\", description)\n",
    "\n",
    "# Convert the description to speech and play it\n",
    "text_to_speech(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "review_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
